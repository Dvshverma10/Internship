{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa32d86",
   "metadata": {},
   "source": [
    "# Assignment-1 : Web Scrapping (Beautiful Soup)\n",
    "\n",
    "**DEVESH VERMA**\n",
    "\n",
    "**BATCH: DS2304**\n",
    "\n",
    "**DATE: 22/05/2023**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f08ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs to be scrapped\n",
    "\n",
    "url1 = 'https://en.wikipedia.org/wiki/Main_Page'\n",
    "\n",
    "url2 = 'https://presidentofindia.nic.in/former-presidents.htm'\n",
    "\n",
    "url3 = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi'\n",
    "\n",
    "url3a = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi'\n",
    "\n",
    "url4 = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi'\n",
    "\n",
    "url4a = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi'\n",
    "\n",
    "url5 = 'https://www.cnbc.com/world/?region=world'\n",
    "\n",
    "url6 = 'https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "\n",
    "url7 = 'https://www.dineout.co.in/delhi-restaurants/buffet-special'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79f1ec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1904b47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Function to fetch content from page\n",
    "\n",
    "def scrap_url(url):\n",
    "    \n",
    "    is_scrappable = requests.get(url)\n",
    "    \n",
    "    if(is_scrappable.status_code ==200):\n",
    "        \n",
    "        soup = BeautifulSoup(is_scrappable.text)\n",
    "        print(url, ': Scrapped Successfully')\n",
    "        \n",
    "    else:\n",
    "        print(url, ': Scrap Request Denied')\n",
    "        soup = 'Scrap Request Denied'\n",
    "        \n",
    "        \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12901ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Function to return list using tag name & class name\n",
    "\n",
    "def tcl_extract(scrap_data, tag_name, class_name):\n",
    "    \n",
    "    res_list= []\n",
    "    \n",
    "    for i in scrap_data.find_all(tag_name, class_=class_name):\n",
    "        \n",
    "        res_list.append(i.text)\n",
    "        \n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71b611ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Function to return list using tag name only\n",
    "\n",
    "def tg_extract(scrap_data, tag_name):\n",
    "    \n",
    "    res_list= []\n",
    "    \n",
    "    for i in scrap_data.find_all(tag_name):\n",
    "        \n",
    "        res_list.append(i.text)\n",
    "        \n",
    "    return res_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "87975404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reyurn list of URLs case of href\n",
    "\n",
    "def href_url(scrap_data, class_name, tag):\n",
    "    \n",
    "    url_lst= []\n",
    "\n",
    "    all_lst = scrap_data.find_all(tag, href=True, class_= class_name)\n",
    "    \n",
    "    urls  = [a['href'] for a in all_lst]\n",
    "    \n",
    "    for url in urls:\n",
    "        url_lst.append(url)\n",
    "        \n",
    "    return url_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c3ff082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create DATAFRAME\n",
    "\n",
    "def get_DF(in_dict):\n",
    "    \n",
    "    return pd.DataFrame(in_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03cd696",
   "metadata": {},
   "source": [
    "**1) Write a python program to display all the header tags from wikipedia.org and make data frame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c17c2bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Main_Page : Scrapped Successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header_Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Header_Tags\n",
       "0                      Main Page\n",
       "1           Welcome to Wikipedia\n",
       "2  From today's featured article\n",
       "3               Did you know ...\n",
       "4                    In the news\n",
       "5                    On this day\n",
       "6       Today's featured picture\n",
       "7       Other areas of Wikipedia\n",
       "8    Wikipedia's sister projects\n",
       "9            Wikipedia languages"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling Function to Scrap URL1\n",
    "\n",
    "soup1 = scrap_url(url1)\n",
    "\n",
    "hdr_list= ['h1', 'h2','h3','h4', 'h5', 'h6']\n",
    "\n",
    "#Extract required tag contents in list\n",
    "\n",
    "wiki_lst = tg_extract(soup1, hdr_list)\n",
    "\n",
    "#Convert to dataframe\n",
    "\n",
    "wiki_DF = pd.DataFrame(columns = ['Header_Tags'], data = wiki_lst)\n",
    "\n",
    "wiki_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff3657d",
   "metadata": {},
   "source": [
    "**2) Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "from https://presidentofindia.nic.in/former-presidents.htm and make data frame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f12738e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://presidentofindia.nic.in/former-presidents.htm : Scrapped Successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Life Span</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>birth - 1945</td>\n",
       "      <td>25 July, 2017 to 25 July, 2022</td>\n",
       "      <td>https://ramnathkovind.nic.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>1935-2020</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "      <td>http://pranabmukherjee.nic.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>birth - 1934</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "      <td>http://pratibhapatil.nic.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>1931-2015</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "      <td>http://abdulkalam.nic.in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>1920 - 2005</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>1918-1999</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>1910-2009</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>1916-1994</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>1913-1996</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>1905-1977</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>1894-1980</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>1897-1969</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>1888-1975</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>1884-1963</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name     Life Span  \\\n",
       "0           Shri Ram Nath Kovind   birth - 1945   \n",
       "1          Shri Pranab Mukherjee      1935-2020   \n",
       "2   Smt Pratibha Devisingh Patil   birth - 1934   \n",
       "3         DR. A.P.J. Abdul Kalam      1931-2015   \n",
       "4           Shri K. R. Narayanan    1920 - 2005   \n",
       "5        Dr Shankar Dayal Sharma      1918-1999   \n",
       "6            Shri R Venkataraman      1910-2009   \n",
       "7               Giani Zail Singh      1916-1994   \n",
       "8      Shri Neelam Sanjiva Reddy      1913-1996   \n",
       "9       Dr. Fakhruddin Ali Ahmed      1905-1977   \n",
       "10  Shri Varahagiri Venkata Giri      1894-1980   \n",
       "11              Dr. Zakir Husain      1897-1969   \n",
       "12  Dr. Sarvepalli Radhakrishnan      1888-1975   \n",
       "13           Dr. Rajendra Prasad      1884-1963   \n",
       "\n",
       "                                               Tenure  \\\n",
       "0                     25 July, 2017 to 25 July, 2022    \n",
       "1                     25 July, 2012 to 25 July, 2017    \n",
       "2                     25 July, 2007 to 25 July, 2012    \n",
       "3                     25 July, 2002 to 25 July, 2007    \n",
       "4                     25 July, 1997 to 25 July, 2002    \n",
       "5                     25 July, 1992 to 25 July, 1997    \n",
       "6                     25 July, 1987 to 25 July, 1992    \n",
       "7                     25 July, 1982 to 25 July, 1987    \n",
       "8                     25 July, 1977 to 25 July, 1982    \n",
       "9                24 August, 1974 to 11 February, 1977   \n",
       "10   3 May, 1969 to 20 July, 1969 and 24 August, 1...   \n",
       "11                        13 May, 1967 to 3 May, 1969   \n",
       "12                       13 May, 1962 to 13 May, 1967   \n",
       "13                   26 January, 1950 to 13 May, 1962   \n",
       "\n",
       "                              URL  \n",
       "0    https://ramnathkovind.nic.in  \n",
       "1   http://pranabmukherjee.nic.in  \n",
       "2     http://pratibhapatil.nic.in  \n",
       "3        http://abdulkalam.nic.in  \n",
       "4                                  \n",
       "5                                  \n",
       "6                                  \n",
       "7                                  \n",
       "8                                  \n",
       "9                                  \n",
       "10                                 \n",
       "11                                 \n",
       "12                                 \n",
       "13                                 "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling Function to Scrap URL2\n",
    "\n",
    "soup2 = scrap_url(url2)\n",
    "\n",
    "#Extract the contents with reqd tag and class\n",
    "\n",
    "pres_det = tcl_extract(soup2, 'div', 'presidentListing')\n",
    "\n",
    "\n",
    "# Define empty list to segregate different datatypes\n",
    "\n",
    "pres_title = []\n",
    "pres_lifespan = []\n",
    "pres_term = []\n",
    "pres_url= []\n",
    "\n",
    "#Splitting & Filling the various datatypes in the separate list \n",
    "\n",
    "for i in pres_det:\n",
    "    \n",
    "    pres_title.append(((i.split('\\n'))[1]).split('(')[0])\n",
    "    \n",
    "    pres_lifespan.append((((i.split('\\n'))[1]).split('(')[1]).split(')')[0])\n",
    "    \n",
    "    pres_term.append(((i.split('\\n'))[2]).split(':')[1])\n",
    "    \n",
    "    pres_url.append((i.split('\\n'))[3])\n",
    "    \n",
    "# Creating Dictionary from populated List \n",
    "\n",
    "pres_dict  = {'Name': pres_title, 'Life Span': pres_lifespan, 'Tenure': pres_term, 'URL': pres_url}\n",
    "    \n",
    "pres_DF = get_DF(pres_dict)\n",
    "\n",
    "pres_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4e396",
   "metadata": {},
   "source": [
    "**3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame**\n",
    "\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "\n",
    "**4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame**\n",
    "\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "21b9d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring required variables\n",
    "\n",
    "st_index = 11\n",
    "end_index = 71\n",
    "jump = 6\n",
    "\n",
    "# Defining the dunction to extract desired elements from extracted list\n",
    "# For 3a, 4a\n",
    "\n",
    "def team_rank_DF(st_index, end_index, jump, in_data_list):\n",
    "    \n",
    "    col_list = ['Rank','Team', 'Matches','Points','Ratings']\n",
    "    rank_list = range(1,11,1)\n",
    "    team_list = in_data_list[st_index:end_index:jump]\n",
    "    mat_list = in_data_list[st_index+1:end_index+1:jump]\n",
    "    pt_list = in_data_list[st_index+2:end_index+2:jump]\n",
    "    rat_list = in_data_list[st_index+3:end_index+3:jump]\n",
    "    \n",
    "    data_list  = [rank_list, team_list, mat_list,pt_list, rat_list]\n",
    "    \n",
    "    team_rank_dict = {k: v for k, v in zip(col_list, data_list)}\n",
    "\n",
    "    return pd.DataFrame(team_rank_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d329aabe",
   "metadata": {},
   "source": [
    "**3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame**\n",
    "\n",
    "a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1ee685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.icc-cricket.com/rankings/mens/team-rankings/odi : Scrapped Successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AUS</td>\n",
       "      <td>23</td>\n",
       "      <td>2,714</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>PAK</td>\n",
       "      <td>20</td>\n",
       "      <td>2,316</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>IND</td>\n",
       "      <td>33</td>\n",
       "      <td>3,807</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NZ</td>\n",
       "      <td>27</td>\n",
       "      <td>2,806</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ENG</td>\n",
       "      <td>24</td>\n",
       "      <td>2,426</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SA</td>\n",
       "      <td>19</td>\n",
       "      <td>1,910</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>BAN</td>\n",
       "      <td>25</td>\n",
       "      <td>2,451</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>AFG</td>\n",
       "      <td>10</td>\n",
       "      <td>878</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>SL</td>\n",
       "      <td>21</td>\n",
       "      <td>1,682</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>WI</td>\n",
       "      <td>25</td>\n",
       "      <td>1,797</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank Team Matches Points Ratings\n",
       "0     1  AUS      23  2,714     118\n",
       "1     2  PAK      20  2,316     116\n",
       "2     3  IND      33  3,807     115\n",
       "3     4   NZ      27  2,806     104\n",
       "4     5  ENG      24  2,426     101\n",
       "5     6   SA      19  1,910     101\n",
       "6     7  BAN      25  2,451      98\n",
       "7     8  AFG      10    878      88\n",
       "8     9   SL      21  1,682      80\n",
       "9    10   WI      25  1,797      72"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling Function to Scrap URL3a\n",
    "\n",
    "soup3a = scrap_url(url3a)\n",
    "\n",
    "# Extract list having required class & tag\n",
    "\n",
    "icc_men_team = tcl_extract(soup3a, 'table', 'table')\n",
    "\n",
    "# Split and separate elements \n",
    "\n",
    "men_team_odi = split_icc_tabs(icc_men_team)\n",
    "\n",
    "# Clean the raw data\n",
    "\n",
    "cl_men_odi_team = clean_icc_data (men_team_odi[0])\n",
    "\n",
    "# Remove white spaces\n",
    "\n",
    "cl_men_odi_team.remove('')\n",
    "\n",
    "# Generate  DataFrame for top 10 teams\n",
    "\n",
    "team_rank_DF(st_index,end_index,jump,cl_men_odi_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a8f4f4",
   "metadata": {},
   "source": [
    "**3) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame**\n",
    "\n",
    "b) Top 10 ODI Batsmen along with the records of their team and rating.\n",
    "\n",
    "c) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95ca8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Function for removing white spaces and separating the elements in the list\n",
    "# For 3b, 3c & 4b, 4c\n",
    "\n",
    "def split_icc_tabs(extr_soup_name):\n",
    "    \n",
    "    p_details = []\n",
    "    \n",
    "    for i in extr_soup_name:\n",
    "        p_details.append((i.split('\\n')))\n",
    "        \n",
    "    return p_details\n",
    "\n",
    "\n",
    "# Cleaning the raw data \n",
    "\n",
    "def clean_icc_data (raw_list):\n",
    "    \n",
    "    cln_list = []\n",
    "          \n",
    "    for i in raw_list:\n",
    "        \n",
    "        if (len(i) !=0):\n",
    "            words = i.split()\n",
    "            cl_i = ' '.join(words)\n",
    "            cln_list.append(cl_i)\n",
    "            \n",
    "    return cln_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41849045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering list from clean data & Generating DataFrame \n",
    "\n",
    "def gen_df(i_lst, ig_txt_lst):\n",
    "    \n",
    "    p_country = []\n",
    "    p_ratings = []\n",
    "    p_name = []\n",
    "    p_rank = []\n",
    "    ignored = 1\n",
    "    \n",
    "\n",
    "    for i in i_lst:\n",
    "        \n",
    "        if((len(i)>2) & (i.isnumeric())):\n",
    "            p_ratings.append(i)\n",
    "            \n",
    "        if((len(i)!=0) &(len(i)<=2) & (i.isnumeric())):\n",
    "            p_rank.append(i)\n",
    "           \n",
    "        if(i.isupper()):\n",
    "            p_country.append(i)\n",
    "            \n",
    "        if((i.count(' ')<=3) & (len(i)>3)):\n",
    "            \n",
    "            if i in ig_txt_lst:\n",
    "                ignored = ignored +1\n",
    "                \n",
    "            else:\n",
    "                p_name.append(i)\n",
    "    \n",
    "    \n",
    "    p_dict = {'Name': p_name,'Rank': p_rank, 'Rating': p_ratings, 'Country': p_country}\n",
    "    \n",
    "    print(len(p_rank), len(p_ratings), len(p_country), len(p_name))\n",
    "    \n",
    "    gen_DF = pd.DataFrame(p_dict)\n",
    "    \n",
    "    \n",
    "    return gen_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3165501a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.icc-cricket.com/rankings/mens/player-rankings/odi : Scrapped Successfully\n"
     ]
    }
   ],
   "source": [
    "# Calling Function to Scrap URL3\n",
    "\n",
    "soup3 = scrap_url(url3)\n",
    "\n",
    "# Extracting the required data from given class and tag\n",
    "\n",
    "icc_men_odi = tcl_extract(soup3, 'div', 'rankings-block__container')\n",
    "\n",
    "# List to filter unwanted elements\n",
    "\n",
    "ig_lst = ['URL Copied', 'Full Table',' ','Player','Share','ODI Batting Rankings','Team','ODI Bowling Rankings','Rating','wodi','ODI All-Rounder Rankings']\n",
    "\n",
    "# Separate the elements and clean the list\n",
    "\n",
    "men_odi = split_icc_tabs(icc_men_odi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "777e8233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>1</td>\n",
       "      <td>886</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>2</td>\n",
       "      <td>777</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>3</td>\n",
       "      <td>755</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imam-ul-Haq</td>\n",
       "      <td>4</td>\n",
       "      <td>745</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>5</td>\n",
       "      <td>738</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>6</td>\n",
       "      <td>726</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>7</td>\n",
       "      <td>722</td>\n",
       "      <td>IRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>8</td>\n",
       "      <td>719</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>9</td>\n",
       "      <td>718</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>10</td>\n",
       "      <td>707</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name Rank Rating Country\n",
       "0             Babar Azam    1    886     PAK\n",
       "1  Rassie van der Dussen    2    777      SA\n",
       "2           Fakhar Zaman    3    755     PAK\n",
       "3            Imam-ul-Haq    4    745     PAK\n",
       "4           Shubman Gill    5    738     IND\n",
       "5           David Warner    6    726     AUS\n",
       "6           Harry Tector    7    722     IRE\n",
       "7            Virat Kohli    8    719     IND\n",
       "8        Quinton de Kock    9    718      SA\n",
       "9           Rohit Sharma   10    707     IND"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the raw data \n",
    "\n",
    "cl_men_odi_bat = clean_icc_data (men_odi[0])\n",
    "\n",
    "# Generating DataFrame for top 10 ODI Batsmen (men)\n",
    "\n",
    "gen_df(cl_men_odi_bat,ig_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2f3bf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>1</td>\n",
       "      <td>705</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>2</td>\n",
       "      <td>691</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>3</td>\n",
       "      <td>686</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>4</td>\n",
       "      <td>667</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>5</td>\n",
       "      <td>660</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>6</td>\n",
       "      <td>659</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>7</td>\n",
       "      <td>652</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>8</td>\n",
       "      <td>637</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mohammad Nabi</td>\n",
       "      <td>9</td>\n",
       "      <td>631</td>\n",
       "      <td>AFG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>10</td>\n",
       "      <td>630</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name Rank Rating Country\n",
       "0    Josh Hazlewood    1    705     AUS\n",
       "1    Mohammed Siraj    2    691     IND\n",
       "2    Mitchell Starc    3    686     AUS\n",
       "3        Matt Henry    4    667      NZ\n",
       "4       Trent Boult    5    660      NZ\n",
       "5       Rashid Khan    6    659     AFG\n",
       "6        Adam Zampa    7    652     AUS\n",
       "7  Mujeeb Ur Rahman    8    637     AFG\n",
       "8     Mohammad Nabi    9    631     AFG\n",
       "9    Shaheen Afridi   10    630     PAK"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning the raw data \n",
    "\n",
    "cl_men_odi_ball = clean_icc_data (men_odi[1])\n",
    "\n",
    "# Generating DataFrame for top 10 ODI Bowlers (men)\n",
    "\n",
    "gen_df(cl_men_odi_ball,ig_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89878c13",
   "metadata": {},
   "source": [
    "**4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame**\n",
    "\n",
    "a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf8446fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.icc-cricket.com/rankings/womens/team-rankings/odi : Scrapped Successfully\n"
     ]
    }
   ],
   "source": [
    "# Calling Function to Scrap URL4a\n",
    "\n",
    "soup4a = scrap_url(url4a)\n",
    "\n",
    "\n",
    "# Extract the contents with reqd tag & class\n",
    "\n",
    "icc_women_team = tcl_extract(soup4a, 'table', 'table')\n",
    "\n",
    "\n",
    "# Split & separate elements\n",
    "\n",
    "women_team_odi = split_icc_tabs(icc_women_team)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1ef0f97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Team</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AUS</td>\n",
       "      <td>21</td>\n",
       "      <td>3,603</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ENG</td>\n",
       "      <td>28</td>\n",
       "      <td>3,342</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SA</td>\n",
       "      <td>26</td>\n",
       "      <td>3,098</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>IND</td>\n",
       "      <td>27</td>\n",
       "      <td>2,820</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NZ</td>\n",
       "      <td>25</td>\n",
       "      <td>2,553</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>WI</td>\n",
       "      <td>27</td>\n",
       "      <td>2,535</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>THA</td>\n",
       "      <td>11</td>\n",
       "      <td>821</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>BAN</td>\n",
       "      <td>14</td>\n",
       "      <td>977</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>PAK</td>\n",
       "      <td>27</td>\n",
       "      <td>1,678</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>SL</td>\n",
       "      <td>9</td>\n",
       "      <td>479</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank Team Matches Points Ratings\n",
       "0     1  AUS      21  3,603     172\n",
       "1     2  ENG      28  3,342     119\n",
       "2     3   SA      26  3,098     119\n",
       "3     4  IND      27  2,820     104\n",
       "4     5   NZ      25  2,553     102\n",
       "5     6   WI      27  2,535      94\n",
       "6     7  THA      11    821      75\n",
       "7     8  BAN      14    977      70\n",
       "8     9  PAK      27  1,678      62\n",
       "9    10   SL       9    479      53"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the list & remove white spaces\n",
    "\n",
    "cl_women_odi_team = clean_icc_data(women_team_odi[0])\n",
    "cl_women_odi_team.remove('')\n",
    "\n",
    "# Call function to Generate required DataFrame\n",
    "\n",
    "team_rank_DF(st_index,end_index,jump,cl_women_odi_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a563f7d3",
   "metadata": {},
   "source": [
    "**4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame**\n",
    "\n",
    "b) Top 10 ODI Bats-women along with the records of their team and rating.\n",
    "\n",
    "c) Top 10 ODI allrounder (Women) along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3de6a396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.icc-cricket.com/rankings/womens/player-rankings/odi : Scrapped Successfully\n"
     ]
    }
   ],
   "source": [
    "# Calling Function to Scrap URL4\n",
    "\n",
    "soup4 = scrap_url(url4)\n",
    "\n",
    "\n",
    "# Extract elemnents with required class & tags\n",
    "\n",
    "icc_women_odi = tcl_extract(soup4, 'div', 'rankings-block__container')\n",
    "\n",
    "\n",
    "# Separate and split the elements in the list\n",
    "\n",
    "women_odi = split_icc_tabs(icc_women_odi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bf1e7d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>1</td>\n",
       "      <td>754</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>2</td>\n",
       "      <td>732</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>3</td>\n",
       "      <td>731</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>4</td>\n",
       "      <td>717</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>5</td>\n",
       "      <td>716</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>6</td>\n",
       "      <td>714</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>7</td>\n",
       "      <td>673</td>\n",
       "      <td>SL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>8</td>\n",
       "      <td>626</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>9</td>\n",
       "      <td>595</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>10</td>\n",
       "      <td>588</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name Rank Rating Country\n",
       "0          Beth Mooney    1    754     AUS\n",
       "1      Laura Wolvaardt    2    732      SA\n",
       "2       Natalie Sciver    3    731     ENG\n",
       "3          Meg Lanning    4    717     AUS\n",
       "4     Harmanpreet Kaur    5    716     IND\n",
       "5      Smriti Mandhana    6    714     IND\n",
       "6  Chamari Athapaththu    7    673      SL\n",
       "7         Ellyse Perry    8    626     AUS\n",
       "8       Tammy Beaumont    9    595     ENG\n",
       "9      Stafanie Taylor   10    588      WI"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the list, remove unwanted and white spaces\n",
    "\n",
    "cl_women_odi_bat = clean_icc_data (women_odi[0])\n",
    "\n",
    "\n",
    "# Create List of elements to be removed\n",
    "\n",
    "wig_lst = ['URL Copied', 'Full Table',' ','Player','Share','ODI Batting Rankings','ODI Bowling Rankings','Team','ODI All-Rounder Rankings','Rating','wodi']\n",
    "\n",
    "\n",
    "# Generate the DataFrame\n",
    "\n",
    "gen_df(cl_women_odi_bat,wig_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d9d6509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>1</td>\n",
       "      <td>373</td>\n",
       "      <td>WI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>2</td>\n",
       "      <td>371</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>3</td>\n",
       "      <td>366</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>4</td>\n",
       "      <td>349</td>\n",
       "      <td>SA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>5</td>\n",
       "      <td>336</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>6</td>\n",
       "      <td>322</td>\n",
       "      <td>IND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>7</td>\n",
       "      <td>292</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>8</td>\n",
       "      <td>250</td>\n",
       "      <td>AUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>9</td>\n",
       "      <td>232</td>\n",
       "      <td>PAK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sophie Ecclestone</td>\n",
       "      <td>10</td>\n",
       "      <td>205</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name Rank Rating Country\n",
       "0    Hayley Matthews    1    373      WI\n",
       "1     Natalie Sciver    2    371     ENG\n",
       "2       Ellyse Perry    3    366     AUS\n",
       "3     Marizanne Kapp    4    349      SA\n",
       "4        Amelia Kerr    5    336      NZ\n",
       "5      Deepti Sharma    6    322     IND\n",
       "6   Ashleigh Gardner    7    292     AUS\n",
       "7      Jess Jonassen    8    250     AUS\n",
       "8           Nida Dar    9    232     PAK\n",
       "9  Sophie Ecclestone   10    205     ENG"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the list, remove unwanted and white spaces\n",
    "\n",
    "cl_women_odi_all = clean_icc_data (women_odi[2])\n",
    "\n",
    "\n",
    "# Define the list of elements to be ignored\n",
    "\n",
    "wig_lst1 = ['URL Copied', 'Full Table',' ','Player','Share','ODI Batting Rankings','ODI Bowler Rankings','Team','ODI All-Rounder Rankings','Rating','wodi']\n",
    "\n",
    "\n",
    "# Generate the DataFrame\n",
    "\n",
    "gen_df(cl_women_odi_all,wig_lst1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede50f4",
   "metadata": {},
   "source": [
    "**5) Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n",
    "make data frame**\n",
    "\n",
    "**i) Headline**\n",
    "\n",
    "**ii) Time**\n",
    "\n",
    "**iii) News Link**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb8f9b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.cnbc.com/world/?region=world : Scrapped Successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Debt ceiling deal will be 'transformational' f...</td>\n",
       "      <td>49 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/debt-ceiling-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYC, Las Vegas, D.C.: Free wellness activities...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/nyc-las-vegas-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Content creators bring in up to $150/hour film...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/content-creato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34-year-old makes up to $167 an hour nannying ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/gloria-richard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This winning fund puts a spin on emerging mark...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/this-winning-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASCO will put the focus on the cancer fight. T...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/asco-will-focu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Now Boarding: Why airlines are turning to bigg...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/now-boarding-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Global demand for streaming Asian movies, TV g...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/squid-game-eea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>These are the cheapest tech stocks in the S&amp;P 500</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/these-are-the-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Turkey votes in runoff election after candidat...</td>\n",
       "      <td>13 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/28/turkey-electio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>White House and Republicans reach a tentative ...</td>\n",
       "      <td>16 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/white-house-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>State Farm to stop accepting homeowners insura...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/state-farm-to-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How Janie Deegan built Janie's Life-Changing B...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/how-janie-deeg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Top 10 cheapest places in the U.S. to buy a be...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/cheapest-place...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mark Cuban calls Elon Musk’s Twitter algorithm...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/mark-cuban-say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3 investing tips as the federal debt ceiling '...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/how-to-invest-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Microsoft keyboard users are ‘devastated’ afte...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/microsoft-keyb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Steve Adcock: The 3 'stupidest' myths I've hea...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/steve-adcock-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Chip stocks AMD and Nvidia are among the most ...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/chip-stocks-am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Analysts are pounding the table for these must...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/analysts-are-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Lower-income consumers pay for wealthy's credi...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/lower-income-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>How Mastercard has outperformed Visa</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/how-mastercard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Why commercial real estate firms are joining t...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/commercial-rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Japan stocks are on fire this year. Why the ra...</td>\n",
       "      <td>May 27, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/27/japan-stocks-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Marvell Technology shares surge after earnings...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/marvell-techno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>The tech trade is back, driven by A.I. craze a...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/tech-stocks-ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Next week hints at only short-lived debt deal ...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/next-week-hint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Treasury says it could run out of money June 5...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/treasury-says-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Disney rips DeSantis bid to disqualify judge i...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/disney-rips-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Why the pause on student loan payments has bee...</td>\n",
       "      <td>May 26, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/05/26/the-pause-on-s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline          Time  \\\n",
       "0   Debt ceiling deal will be 'transformational' f...    49 Min Ago   \n",
       "1   NYC, Las Vegas, D.C.: Free wellness activities...   3 Hours Ago   \n",
       "2   Content creators bring in up to $150/hour film...   3 Hours Ago   \n",
       "3   34-year-old makes up to $167 an hour nannying ...   4 Hours Ago   \n",
       "4   This winning fund puts a spin on emerging mark...   4 Hours Ago   \n",
       "5   ASCO will put the focus on the cancer fight. T...   4 Hours Ago   \n",
       "6   Now Boarding: Why airlines are turning to bigg...   5 Hours Ago   \n",
       "7   Global demand for streaming Asian movies, TV g...   5 Hours Ago   \n",
       "8   These are the cheapest tech stocks in the S&P 500   5 Hours Ago   \n",
       "9   Turkey votes in runoff election after candidat...  13 Hours Ago   \n",
       "10  White House and Republicans reach a tentative ...  16 Hours Ago   \n",
       "11  State Farm to stop accepting homeowners insura...  22 Hours Ago   \n",
       "12  How Janie Deegan built Janie's Life-Changing B...  May 27, 2023   \n",
       "13  Top 10 cheapest places in the U.S. to buy a be...  May 27, 2023   \n",
       "14  Mark Cuban calls Elon Musk’s Twitter algorithm...  May 27, 2023   \n",
       "15  3 investing tips as the federal debt ceiling '...  May 27, 2023   \n",
       "16  Microsoft keyboard users are ‘devastated’ afte...  May 27, 2023   \n",
       "17  Steve Adcock: The 3 'stupidest' myths I've hea...  May 27, 2023   \n",
       "18  Chip stocks AMD and Nvidia are among the most ...  May 27, 2023   \n",
       "19  Analysts are pounding the table for these must...  May 27, 2023   \n",
       "20  Lower-income consumers pay for wealthy's credi...  May 27, 2023   \n",
       "21               How Mastercard has outperformed Visa  May 27, 2023   \n",
       "22  Why commercial real estate firms are joining t...  May 27, 2023   \n",
       "23  Japan stocks are on fire this year. Why the ra...  May 27, 2023   \n",
       "24  Marvell Technology shares surge after earnings...  May 26, 2023   \n",
       "25  The tech trade is back, driven by A.I. craze a...  May 26, 2023   \n",
       "26  Next week hints at only short-lived debt deal ...  May 26, 2023   \n",
       "27  Treasury says it could run out of money June 5...  May 26, 2023   \n",
       "28  Disney rips DeSantis bid to disqualify judge i...  May 26, 2023   \n",
       "29  Why the pause on student loan payments has bee...  May 26, 2023   \n",
       "\n",
       "                                                  URL  \n",
       "0   https://www.cnbc.com/2023/05/28/debt-ceiling-d...  \n",
       "1   https://www.cnbc.com/2023/05/28/nyc-las-vegas-...  \n",
       "2   https://www.cnbc.com/2023/05/28/content-creato...  \n",
       "3   https://www.cnbc.com/2023/05/28/gloria-richard...  \n",
       "4   https://www.cnbc.com/2023/05/28/this-winning-f...  \n",
       "5   https://www.cnbc.com/2023/05/28/asco-will-focu...  \n",
       "6   https://www.cnbc.com/2023/05/28/now-boarding-a...  \n",
       "7   https://www.cnbc.com/2023/05/28/squid-game-eea...  \n",
       "8   https://www.cnbc.com/2023/05/28/these-are-the-...  \n",
       "9   https://www.cnbc.com/2023/05/28/turkey-electio...  \n",
       "10  https://www.cnbc.com/2023/05/27/white-house-an...  \n",
       "11  https://www.cnbc.com/2023/05/27/state-farm-to-...  \n",
       "12  https://www.cnbc.com/2023/05/27/how-janie-deeg...  \n",
       "13  https://www.cnbc.com/2023/05/27/cheapest-place...  \n",
       "14  https://www.cnbc.com/2023/05/27/mark-cuban-say...  \n",
       "15  https://www.cnbc.com/2023/05/27/how-to-invest-...  \n",
       "16  https://www.cnbc.com/2023/05/27/microsoft-keyb...  \n",
       "17  https://www.cnbc.com/2023/05/27/steve-adcock-t...  \n",
       "18  https://www.cnbc.com/2023/05/27/chip-stocks-am...  \n",
       "19  https://www.cnbc.com/2023/05/27/analysts-are-p...  \n",
       "20  https://www.cnbc.com/2023/05/27/lower-income-a...  \n",
       "21  https://www.cnbc.com/2023/05/27/how-mastercard...  \n",
       "22  https://www.cnbc.com/2023/05/27/commercial-rea...  \n",
       "23  https://www.cnbc.com/2023/05/27/japan-stocks-a...  \n",
       "24  https://www.cnbc.com/2023/05/26/marvell-techno...  \n",
       "25  https://www.cnbc.com/2023/05/26/tech-stocks-ar...  \n",
       "26  https://www.cnbc.com/2023/05/26/next-week-hint...  \n",
       "27  https://www.cnbc.com/2023/05/26/treasury-says-...  \n",
       "28  https://www.cnbc.com/2023/05/26/disney-rips-de...  \n",
       "29  https://www.cnbc.com/2023/05/26/the-pause-on-s...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling Function to Scrap URL6\n",
    "\n",
    "soup5 = scrap_url(url5)\n",
    "\n",
    "\n",
    "# Extracting the required datatypes with required tags & class\n",
    "\n",
    "time_lst = tcl_extract(soup5, 'time', 'LatestNews-timestamp')\n",
    "\n",
    "news_lst = tcl_extract(soup5,'a', 'LatestNews-headline')\n",
    "\n",
    "nurl_lst = href_url(soup5, 'LatestNews-headline', 'a')\n",
    "\n",
    "\n",
    "# Create Dictionary\n",
    "\n",
    "news_dict = {'Headline': news_lst, 'Time': time_lst, 'URL': nurl_lst}\n",
    "\n",
    "\n",
    "# Call function to generate Dataframe\n",
    "\n",
    "latest_news_DF = get_DF(news_dict)\n",
    "\n",
    "latest_news_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fa2d56",
   "metadata": {},
   "source": [
    "**6) Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details and make data frame**\n",
    "\n",
    "\u0002i) Paper Title\n",
    "\n",
    "ii) Authors\n",
    "\n",
    "iii) Published Date\n",
    "\n",
    "iv) Paper URL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a643c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles : Scrapped Successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publish Date</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                    Reward is enough   \n",
       "1   Explanation in artificial intelligence: Insigh...   \n",
       "2              Creativity and artificial intelligence   \n",
       "3   Conflict-based search for optimal multi-agent ...   \n",
       "4   Knowledge graphs as tools for explainable mach...   \n",
       "5   Law and logic: A review from an argumentation ...   \n",
       "6   Between MDPs and semi-MDPs: A framework for te...   \n",
       "7   Explaining individual predictions when feature...   \n",
       "8       Multiple object tracking: A literature review   \n",
       "9   A survey of inverse reinforcement learning: Ch...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11  Explainable AI tools for legal reasoning about...   \n",
       "12            Hard choices in artificial intelligence   \n",
       "13  Assessing the communication gap between AI mod...   \n",
       "14  Explaining black-box classifiers using post-ho...   \n",
       "15  The Hanabi challenge: A new frontier for AI re...   \n",
       "16              Wrappers for feature subset selection   \n",
       "17  Artificial cognition for social human–robot in...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  The multifaceted impact of Ada Lovelace in the...   \n",
       "20  Robot ethics: Mapping the issues for a mechani...   \n",
       "21          Reward (Mis)design for autonomous driving   \n",
       "22  Planning and acting in partially observable st...   \n",
       "23  What do we want from Explainable Artificial In...   \n",
       "\n",
       "                                              Authors    Publish Date  \\\n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
       "1                                         Tim Miller    February 2019   \n",
       "2                                  Margaret A. Boden      August 1998   \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
       "4                     Ilaria Tiddi, Stefan Schlobach     January 2022   \n",
       "5                     Henry Prakken, Giovanni Sartor     October 2015   \n",
       "6    Richard S. Sutton, Doina Precup, Satinder Singh      August 1999   \n",
       "7          Kjersti Aas, Martin Jullum, Anders Løland   September 2021   \n",
       "8                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
       "9                      Saurabh Arora, Prashant Doshi      August 2021   \n",
       "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
       "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
       "12  Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz    November 2021   \n",
       "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
       "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
       "15          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
       "16                        Ron Kohavi, George H. John    December 1997   \n",
       "17      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
       "18   Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz        June 2021   \n",
       "19                            Luigia Carlucci Aiello        June 2016   \n",
       "20            Patrick Lin, Keith Abney, George Bekey       April 2011   \n",
       "21     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023   \n",
       "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
       "23             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
       "\n",
       "                                                  URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling Function to Scrap URL6\n",
    "\n",
    "soup6 = scrap_url(url6)\n",
    "\n",
    "# Extracting the required datatypes with required tags & class\n",
    "\n",
    "p_title = tcl_extract(soup6, 'h2', 'sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg')\n",
    "\n",
    "p_author = tcl_extract(soup6,'span', 'sc-1w3fpd7-0 dnCnAO')\n",
    "\n",
    "p_pubdate = tcl_extract(soup6,'span', 'sc-1thf9ly-2 dvggWt')\n",
    "\n",
    "p_url = href_url(soup6, 'sc-5smygv-0 fIXTHm', 'a')\n",
    "\n",
    "# Creating Dictionaries\n",
    "\n",
    "p_dict = {'Title': p_title, 'Authors': p_author, 'Publish Date': p_pubdate, 'URL': p_url}\n",
    "\n",
    "# Call function to generate DataFrame\n",
    "\n",
    "paper_DF = get_DF(p_dict)\n",
    "\n",
    "paper_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdcf020",
   "metadata": {},
   "source": [
    "**7) Write a python program to scrape mentioned details from dineout.co.in and make data frame**\n",
    "\n",
    "i) Restaurant name\n",
    "\n",
    "ii) Cuisine\n",
    "\n",
    "iii) Location\n",
    "\n",
    "iv) Ratings\n",
    "\n",
    "v) Image URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3ddb6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.dineout.co.in/delhi-restaurants/buffet-special : Scrapped Successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>/delhi/castle-barbeque-connaught-place-central...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian, Asian, Italian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>/delhi/jungle-jamboree-lajpat-nagar-3-south-de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>/delhi/cafe-knosh-shahdara-east-delhi-406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Castle's Barbeque</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>/delhi/castles-barbeque-tagore-garden-west-del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>3.9</td>\n",
       "      <td>/delhi/the-barbeque-company-sector-38a-noida-7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>/delhi/india-grill-saket-south-delhi-2687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>/delhi/delhi-barbeque-mahipalpur-south-delhi-5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>/delhi/the-monarch-bar-be-que-village-indirapu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>/delhi/indian-grill-room-golf-course-road-gurg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Restaurant                        Cuisine  \\\n",
       "0                   Castle Barbeque          Chinese, North Indian   \n",
       "1                   Jungle Jamboree   North Indian, Asian, Italian   \n",
       "2                        Cafe Knosh           Italian, Continental   \n",
       "3                 Castle's Barbeque          Chinese, North Indian   \n",
       "4              The Barbeque Company          North Indian, Chinese   \n",
       "5                       India Grill          North Indian, Italian   \n",
       "6                    Delhi Barbeque                   North Indian   \n",
       "7  The Monarch - Bar Be Que Village                   North Indian   \n",
       "8                 Indian Grill Room          North Indian, Mughlai   \n",
       "\n",
       "                                            Location Ratings  \\\n",
       "0                     Connaught Place, Central Delhi       4   \n",
       "1             3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2  The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "3             Pacific Mall,Tagore Garden, West Delhi     3.9   \n",
       "4                 Gardens Galleria,Sector 38A, Noida     3.9   \n",
       "5               Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6     Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7   \n",
       "7  Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8   \n",
       "8   Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "\n",
       "                                                 URL  \n",
       "0  /delhi/castle-barbeque-connaught-place-central...  \n",
       "1  /delhi/jungle-jamboree-lajpat-nagar-3-south-de...  \n",
       "2          /delhi/cafe-knosh-shahdara-east-delhi-406  \n",
       "3  /delhi/castles-barbeque-tagore-garden-west-del...  \n",
       "4  /delhi/the-barbeque-company-sector-38a-noida-7...  \n",
       "5          /delhi/india-grill-saket-south-delhi-2687  \n",
       "6  /delhi/delhi-barbeque-mahipalpur-south-delhi-5...  \n",
       "7  /delhi/the-monarch-bar-be-que-village-indirapu...  \n",
       "8  /delhi/indian-grill-room-golf-course-road-gurg...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling Function to Scrap URL7\n",
    "\n",
    "soup7 = scrap_url(url7)\n",
    "\n",
    "# Extracting the required datatypes with required tags & class\n",
    "\n",
    "do_name = tcl_extract(soup7, 'a', 'restnt-name ellipsis')\n",
    "\n",
    "do_loc = tcl_extract(soup7,'div', 'restnt-loc ellipsis')\n",
    "\n",
    "do_rate = tcl_extract(soup7,'div', 'restnt-rating rating-4')\n",
    "\n",
    "do_url = href_url(soup7, 'restnt-name ellipsis', 'a')\n",
    "\n",
    "do_specs = tcl_extract(soup7,'span', 'double-line-ellipsis')\n",
    "\n",
    "do_cuis = []\n",
    "\n",
    "# Split using separator\n",
    "\n",
    "for i in do_specs:\n",
    "    \n",
    "    do_cuis.append((i.split('|'))[-1])\n",
    "\n",
    "# Create Dictionary\n",
    "\n",
    "dine_del_dict = {'Restaurant': do_name, 'Cuisine': do_cuis, 'Location': do_loc, 'Ratings': do_rate, 'URL': do_url}\n",
    "\n",
    "# Generate DataFrame\n",
    "\n",
    "del_dine_DF = get_DF(dine_del_dict)\n",
    "\n",
    "del_dine_DF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
